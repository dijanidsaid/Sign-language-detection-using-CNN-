{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b389285f-223a-4eae-a32a-a9e122eef14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "215/215 [==============================] - 74s 336ms/step - loss: 1.0319 - accuracy: 0.6771 - val_loss: 4.5816 - val_accuracy: 0.0686 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 72s 336ms/step - loss: 0.2134 - accuracy: 0.9304 - val_loss: 1.3828 - val_accuracy: 0.5690 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 71s 332ms/step - loss: 0.1039 - accuracy: 0.9665 - val_loss: 0.1706 - val_accuracy: 0.9339 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 72s 335ms/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: 0.2298 - val_accuracy: 0.9262 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 77s 356ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.0438 - val_accuracy: 0.9845 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "215/215 [==============================] - 89s 412ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0371 - val_accuracy: 0.9877 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 87s 403ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.1440 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9906\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 75s 350ms/step - loss: 0.0303 - accuracy: 0.9906 - val_loss: 0.1346 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 88s 408ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0143 - val_accuracy: 0.9950 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "215/215 [==============================] - 105s 487ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0058 - val_accuracy: 0.9976 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - 102s 473ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0058 - val_accuracy: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "215/215 [==============================] - 84s 389ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0411 - val_accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 76s 351ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0192 - val_accuracy: 0.9927 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "215/215 [==============================] - 73s 337ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - 73s 337ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "215/215 [==============================] - 71s 332ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0031 - val_accuracy: 0.9989 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 73s 338ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9997 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "215/215 [==============================] - 71s 332ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "215/215 [==============================] - 73s 339ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9997 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "215/215 [==============================] - 72s 332ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0010 - val_accuracy: 0.9997 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"sign_mnist_test.csv\")\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "del train_df['label']\n",
    "del test_df['label']\n",
    "\n",
    "# One-hot encode labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.transform(y_test)\n",
    "\n",
    "# Normalize data\n",
    "x_train = train_df.values / 255.0\n",
    "x_test = test_df.values / 255.0\n",
    "\n",
    "# Reshape data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Learning rate reduction\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(75, (3, 3), strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), strides=2, padding='same'),\n",
    "    Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), strides=2, padding='same'),\n",
    "    Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), strides=2, padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=20, validation_data=(x_test, y_test), callbacks=[learning_rate_reduction])\n",
    "\n",
    "# Save model\n",
    "model.save('ourdata.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1646a3-154c-4bef-a5c7-b53a7f04e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 495ms/step\n",
      "Predicted Character 1: P, Confidence: 67.82%\n",
      "Predicted Character 2: F, Confidence: 31.94%\n",
      "Predicted Character 3: A, Confidence: 0.22%\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('ourdata.h5')\n",
    "\n",
    "# Initialize Mediapipe hands model\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "_, frame = cap.read()\n",
    "h, w, c = frame.shape\n",
    "analysisframe = ''\n",
    "letterpred = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \n",
    "              'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    k = cv2.waitKey(1)\n",
    "    \n",
    "    if k % 256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "\n",
    "    if hand_landmarks:\n",
    "        for handLMs in hand_landmarks:\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "\n",
    "            y_min -= 20\n",
    "            y_max += 20\n",
    "            x_min -= 20\n",
    "            x_max += 20\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            mp_drawing.draw_landmarks(frame, handLMs, mphands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if k % 256 == 32:\n",
    "        # SPACE pressed\n",
    "        analysisframe = frame\n",
    "        showframe = analysisframe\n",
    "        cv2.imshow(\"Frame\", showframe)\n",
    "        framergbanalysis = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2RGB)\n",
    "        resultanalysis = hands.process(framergbanalysis)\n",
    "        hand_landmarksanalysis = resultanalysis.multi_hand_landmarks\n",
    "        \n",
    "        if hand_landmarksanalysis:\n",
    "            for handLMsanalysis in hand_landmarksanalysis:\n",
    "                x_max = 0\n",
    "                y_max = 0\n",
    "                x_min = w\n",
    "                y_min = h\n",
    "                \n",
    "                for lmanalysis in handLMsanalysis.landmark:\n",
    "                    x, y = int(lmanalysis.x * w), int(lmanalysis.y * h)\n",
    "                    if x > x_max:\n",
    "                        x_max = x\n",
    "                    if x < x_min:\n",
    "                        x_min = x\n",
    "                    if y > y_max:\n",
    "                        y_max = y\n",
    "                    if y < y_min:\n",
    "                        y_min = y\n",
    "\n",
    "                y_min -= 20\n",
    "                y_max += 20\n",
    "                x_min -= 20\n",
    "                x_max += 20\n",
    "\n",
    "                # Extract the region of interest (hand sign)\n",
    "                analysisframe_roi = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2GRAY)\n",
    "                analysisframe_roi = analysisframe_roi[y_min:y_max, x_min:x_max]\n",
    "                analysisframe_roi = cv2.resize(analysisframe_roi, (28, 28))\n",
    "\n",
    "                # Prepare data for prediction\n",
    "                pixeldata = analysisframe_roi.astype('float32') / 255.0\n",
    "                pixeldata = np.expand_dims(pixeldata, axis=-1)\n",
    "                pixeldata = np.expand_dims(pixeldata, axis=0)\n",
    "\n",
    "                # Make prediction\n",
    "                prediction = model.predict(pixeldata)\n",
    "                predarray = prediction[0]\n",
    "                pred_indexes_sorted = np.argsort(predarray)[::-1][:3]\n",
    "\n",
    "                # Display predictions\n",
    "                for idx, pred_idx in enumerate(pred_indexes_sorted):\n",
    "                    predicted_char = letterpred[pred_idx]\n",
    "                    confidence = predarray[pred_idx] * 100\n",
    "                    print(f\"Predicted Character {idx + 1}: {predicted_char}, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "        time.sleep(5)  # Wait for 5 seconds before processing the next frame\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3187dc-ff29-469f-88fc-722bb02f2751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9aa10-427d-416e-b065-5805fbb126f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4228af6c-be11-4ac4-89ac-8607722740eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
